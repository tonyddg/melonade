#import "/book.typ": book-page, cross-link, templates
#show: book-page.with(title: "自编码器")

#import "/utility/widget.typ": *

= 自编码器

== 自编码器的概念

#link("https://www.bilibili.com/video/BV1Wv411h7kN?p=83")[参考教程]

=== 自监督学习概念

自监督学习方法（Self-supervise learning）为不需要标签的模型训练方法，为了训练模型就需要人为设计这种不需要标签的任务，如 GPT 中预测文本中下一个单词，这种方式训练的模型通常需要微调后才能用于后续（下游）具体任务，因此也称为 Pre-training

=== 自编码器的结构

#figure(
  image("res/ae_1.png", height: 10em), 
  caption: [自编码器的结构],
)

自编码器中包含了一个编码器和解码器，编码器提取一个高维的输入向量（如图片）为低维的特征向量；解码器则是接收这个特征向量输入，重建原始的高维输入。自编码器的目标即让编码器的输入与解码器的输出越接近越好。

一般将自编码器训练得到的编码器用于压缩高维输入，将输出的特征向量用于下游任务。因此特征向量一般称为 Embedding 或 Code，这个过程称为 Dimension Reduction。

== 自编码器的应用

对于现实图片来说，虽然图片是一个高维向量，但往往会符合某些特点而变化优先。因此只要找出所有变化参数，就可以用一个低维变量描述复杂的图片。

=== 去噪自编码器

#figure(
  image("res/ae_2.png", height: 10em), 
  caption: [去噪自编码器],
)

称为 De-noising auto-encoder，来自 #link("https://dl.acm.org/doi/10.1145/1390156.1390294")

去噪自编码器属于自编码器的应用之一，可以在输入图片中加入噪音，要求解码器输出不含噪音的原始图片。在文字处理领域有如 BERT，在输入文字序列中加入遮罩，输出序列还原原来的文字序列。

除此之外，在一般编码器内对输入样本加入噪音也可以提高整体的稳健性。

=== 特性解耦

#figure(
  image("res/ae_3.png", height: 10em), 
  caption: [特性解耦],
)

通过某些方法分析特征向量各个元素的含义，可以划分为风格与内容两个部分，从而人工合成特征向量传入解码器，得到所需风格与内容的输出（如图片、语音、文章）。

=== 离散表示

#figure(
  image("res/ae_4.png", height: 10em), 
  caption: [离散表示],
)

强制特征向量的元素为离散值，可以更容易地区分各个特征的效果；强制特征向量为 One-hot，可以将特征向量用于分类。

=== 异常检测

#figure(
  image("res/ae_5.png", height: 10em), 
  caption: [异常检测],
)

异常检测的一种方法可通过自编码器实现。自编码器训练时，通常只能还原与训练样本同类的输入，因此一旦出现异常样本解码器就无法还原，体现为出现较大的重建损失，由此判断出现异常。

=== 图像搜索

利用编码得到的特征向量，计算图像间特征向量的距离可以得到图像间的相似性。

== 变分自编码器

参考教程
- #link("https://www.bilibili.com/video/BV1Gx411E7Ha?p=35")
- #link("https://blog.csdn.net/a312863063/article/details/87953517")

变分自编码器称为 VAE，来自 #link("https://dl.acm.org/doi/10.1145/1390156.1390294")，VAE 主要用于解决如何将解码器用于可控的样本生成

=== 变分自编码器的提出

当自编码器训练好后，一个特征向量严格对应一个训练样本，因此训练集样本输入输出的相似性很好。然而即使稍微调整特征向量某个属性很可能输出为无法辨认的乱码，解码器只是几个特征向量的非线性映射没有内插能力，因此一般的解码器基本不具有生成能力。

#figure(
  image("res/ae_6.png", height: 10em), 
  caption: [在特性上加入噪音],
)

一种简单的做法即在编码器输出的特征向量上加上噪音，要求解码器对真实特征向量附近的向量均重建回样本，同时保证输入解码器的特征向量覆盖整个特征向量空间。同时当两个样本相近时，可能出现同一特征向量同时指向两个样本的情景，从而使解码器生成两者中间的结果以达到最优，此时的特征向量真正具有表达样本特性的能力而不是简单压缩。

简单加上噪音也无法保证覆盖整个特征向量空间，同时当特征向量偏移过远可能导致编码器无法正确学习。因此更好地方法是让噪音符合某种分布如正态分布，既能保证噪音覆盖整个向量空间，偏离编码器特征向量越远越少的特点出现也能让解码器正确理解连续变化的特征属性值进行内插而不是简单映射。

=== 变分自编码器的结构

#figure(
  image("res/ae_7.png", height: 10em), 
  caption: [变分自编码器的结构],
) <vae_struct>

变分自编码器中，编码器除了预测样本的特征向量，即均值 $m$，还会预测误差的幅值，如正态分布的方差 $sigma$，再乘上采样自正态分布的随机数得到符合正态分布的噪音（该方法能保证误差输出的反向传播），加上均值作为传入解码器的特征向量。

#figure(
  image("res/ae_8.png", height: 10em), 
  caption: [函数 $exp(sigma_i)-(1+sigma_i)$ 的图像（绿线）],
) <reg_sigma>

为了防止模型学会抑制方差输出 $sigma$ 避免噪音干扰，还要加入额外的正则化目标，如#ref(<vae_struct>) 中的公式包含了两个正则化（以最小化为目标）
- $exp(sigma_i)-(1+sigma_i)$ 图像如 #ref(<reg_sigma>)，容忍初期使用较小的方差规避噪音扰动，但最终将方差调整为期望值 1
- $m_i^2$ 即 L2 正则，将特征向量限制在 0 附近便于调整特征向量

上述说明为直觉角度，关于从严格数学角度的说明可参见教程

=== CVAE 条件变分自编码器

参考 #link("https://zhuanlan.zhihu.com/p/642406552")

条件变分自编码器称为 CVAE，来自 #link("https://arxiv.org/pdf/1406.5298")，主要用于解决如何将解码器用于可控的样本生成

VAE 虽然解决了连续变化的问题，但特征向量各个属性调整效果都是不可预知的，以然无法让生成的样本向预期变化。

一种解决方法即在特征向量之外提供样本的标签（即希望样本可控的特性）作为属性，此时就能保证特征向量里这些额外属性是可控的，而编码器的任务变为提取样本中其他特征。

#figure(
  image("res/ae_9.jpg", height: 10em), 
  caption: [CVAE 的一种结构],
)

CVAE 的一种结构如上图所示，此外还有多种结合方式如将标签的 One-hot 编码与原始特征向量拼接等。

#figure(
  image("res/ae_10.png", height: 10em), 
  caption: [CVAE 的风格迁移应用],
)

CVAE 主要能够用于风格迁移等任务，如图编码器负责提取图片的风格特征，解码器接收整合了数字标签的特征向量后生成类似风格的图片。
